{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Data augmentation research** #"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:24:12.106723Z","iopub.status.busy":"2023-11-30T15:24:12.105874Z","iopub.status.idle":"2023-11-30T15:24:12.111809Z","shell.execute_reply":"2023-11-30T15:24:12.110783Z","shell.execute_reply.started":"2023-11-30T15:24:12.106691Z"},"trusted":true},"outputs":[],"source":["import librosa\n","import soundfile as sf\n","import os\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow import keras\n","import shutil\n","import cv2\n","import matplotlib.pyplot as plt\n","import multiprocessing\n","import concurrent.futures\n","from time import perf_counter"]},{"cell_type":"markdown","metadata":{},"source":["**The following cell is for clearing the output directory from kaggle; run it only if needed**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-29T23:39:08.339714Z","iopub.status.busy":"2023-11-29T23:39:08.338957Z","iopub.status.idle":"2023-11-29T23:39:08.379278Z","shell.execute_reply":"2023-11-29T23:39:08.378403Z","shell.execute_reply.started":"2023-11-29T23:39:08.339683Z"},"trusted":true},"outputs":[],"source":["# Specify the path to the output directory\n","output_directory = \"/kaggle/working/\"\n","\n","# Iterate through the files and subdirectories in the output directory\n","for item in os.listdir(output_directory):\n","    item_path = os.path.join(output_directory, item)\n","    if os.path.isfile(item_path):\n","        os.remove(item_path)\n","    elif os.path.isdir(item_path):\n","        shutil.rmtree(item_path)\n","\n","print(\"Output directory cleared.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:24:26.184588Z","iopub.status.busy":"2023-11-30T15:24:26.184239Z","iopub.status.idle":"2023-11-30T15:24:27.157784Z","shell.execute_reply":"2023-11-30T15:24:27.156477Z","shell.execute_reply.started":"2023-11-30T15:24:26.184559Z"},"trusted":true},"outputs":[],"source":["os.makedirs(\"Spectrograms_computed\")\n","filenames = ['blues', 'classical', 'country', 'disco', 'hiphop','jazz', 'metal', 'pop', 'reggae', 'rock']\n","\n","for filename in filenames:\n","    os.makedirs(\"Spectrograms_computed/\"+filename)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:24:38.992234Z","iopub.status.busy":"2023-11-30T15:24:38.991540Z","iopub.status.idle":"2023-11-30T15:24:39.002271Z","shell.execute_reply":"2023-11-30T15:24:39.001233Z","shell.execute_reply.started":"2023-11-30T15:24:38.992204Z"},"trusted":true},"outputs":[],"source":["'Define the function to compute and save the spectograms'\n","\n","def spectrogram_creation(audio_path, song_name, spectrogram_save_path, segment_duration=30, num_segments=1, augmentation_percentage=-1):\n","    # Load audio file\n","    y, sr = librosa.load(audio_path)\n","\n","    # Create Figure and Axes objects\n","    fig, ax = plt.subplots(figsize=(10, 4))\n","\n","    for segment_index in range(num_segments):\n","        start_sample = int(segment_index * segment_duration * sr)\n","        end_sample = int((segment_index + 1) * segment_duration * sr)\n","\n","        # Extract the segment from the loaded audio\n","        y_segment = y[start_sample:end_sample]\n","        \n","        # Apply augmentation with a certain probability\n","        if np.random.rand() < augmentation_percentage:\n","            spectrogram_save_path = spectrogram_save_path + \"Aug\"\n","            y_segment = apply_random_augmentation(y_segment, sr)\n","\n","        # Compute the spectrogram for the segment and convert to dB\n","        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n","        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n","\n","        # Plot the spectrogram on the existing Axes\n","        librosa.display.specshow(spectrogram_db)\n","\n","        # Save the figure to the file\n","        fig.savefig(f'{spectrogram_save_path}_segment_{segment_index + 1}-{song_name}.png')\n","\n","        # Clear the existing plot for the next iteration\n","        ax.cla()\n","\n","    # Close the Figure to release resources\n","    plt.close(fig)\n","\n","# Choose a random data augmentation method to apply on the signal\n","def apply_random_augmentation(signal, sr):\n","    # Randomly choose an augmentation function or return the original signal\n","    augmentation_functions = [add_white_noise, pitch_scale, random_gain, nothing]\n","    # augmentation_functions = [nothing]\n","    chosen_function = np.random.choice(augmentation_functions)\n","\n","    # Apply the chosen augmentation function\n","    augmented_signal = chosen_function(signal, sr)\n","\n","    return augmented_signal\n","\n","def nothing(signal, sr):\n","    return signal\n","\n","def add_white_noise(signal, sr, noise_percentage_factor=0.005):\n","    noise = np.random.normal(0, signal.std(), signal.size)\n","    augmented_signal = signal + noise * noise_percentage_factor\n","    return augmented_signal\n","\n","def pitch_scale(signal, sr, num_semitones=2):\n","    return librosa.effects.pitch_shift(y=signal, sr=sr, n_steps=num_semitones)\n","\n","def random_gain(signal, sr, min_factor=0.8, max_factor=1.2):\n","    gain_rate = np.random.uniform(min_factor, max_factor)\n","    augmented_signal = signal * gain_rate\n","    return augmented_signal\n"]},{"cell_type":"markdown","metadata":{},"source":["One audios from the dataset is not used: \n","\n","* one audio that cannot be loaded neither with librosa or soundfile libraries.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:24:49.640427Z","iopub.status.busy":"2023-11-30T15:24:49.640055Z","iopub.status.idle":"2023-11-30T15:27:54.662188Z","shell.execute_reply":"2023-11-30T15:27:54.660975Z","shell.execute_reply.started":"2023-11-30T15:24:49.640397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/metal/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/reggae/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/blues/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/disco\n","\n","\n","\n","/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/rock\n","/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/classical\n","/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz\n","/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/hiphop\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_32/1078951517.py:28: UserWarning: PySoundFile failed. Trying audioread instead.\n","  y, sr = librosa.load(audio_path)\n","/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\n","/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/country\n","/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/pop\n","Total time: 3.0835197758333304\n"]}],"source":["'Iterate throught the genres folders, compute the spectograms and create the new spectrogram dataset'\n","\n","dataset_path = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original'\n","spec_path = '/kaggle/working/Spectrograms_computed/'\n","\n","dataset_spec = []\n","\n","# if multi-threading spectrogram creation uncomment this line, otherwise comment this line\n","# plt.switch_backend('agg')\n","\n","# Multi-processing\n","def process_genre(genre):\n","    count_song_genre = 1\n","    genre_path = os.path.join(dataset_path, genre)\n","    print(genre_path)\n","    for song in os.listdir(genre_path):\n","        song_path = os.path.join(genre_path, song)\n","        # Split the string on the period (.)\n","        split_words = song.split('.')\n","\n","        # Take the first two words and concatenate them with an underscore\n","        song = '.'.join(split_words[:2])\n","        try:\n","            spec_path_genre = f\"{spec_path}{genre}/\"\n","            spectrogram_creation(song_path,  song, f\"{spec_path_genre}{genre}{count_song_genre}\")\n","            count_song_genre += 1\n","        except Exception as e:\n","            print(e)\n","        \n","start = perf_counter()\n","with multiprocessing.Pool() as pool:\n","        genres = os.listdir(dataset_path)\n","        pool.map(process_genre, genres)\n","end = perf_counter()\n","\n","print(f\"Total time: {(end-start) / 60}\")\n","                \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Check if the number of files from each directory is Correct**"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:28:06.106431Z","iopub.status.busy":"2023-11-30T15:28:06.105485Z","iopub.status.idle":"2023-11-30T15:28:06.115152Z","shell.execute_reply":"2023-11-30T15:28:06.114246Z","shell.execute_reply.started":"2023-11-30T15:28:06.106393Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory: /kaggle/working/Spectrograms_computed, File Count: 0\n","Directory: /kaggle/working/Spectrograms_computed/jazz, File Count: 99\n","Directory: /kaggle/working/Spectrograms_computed/metal, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/country, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/blues, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/classical, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/pop, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/reggae, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/disco, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/rock, File Count: 100\n","Directory: /kaggle/working/Spectrograms_computed/hiphop, File Count: 100\n"]}],"source":["# Define the parent directory you want to analyze\n","parent_directory = '/kaggle/working/Spectrograms_computed'\n","# parent_directory = \"/kaggle/input/gtzan-dataset-music-genre-classification/Data/images_original\"\n","\n","# Create an empty dictionary to store directory names and file counts\n","directory_file_counts = {}\n","\n","# Walk through the parent directory and count files in each subdirectory\n","for root, dirs, files in os.walk(parent_directory):\n","    # Count the files in the current directory\n","    file_count = len(files)\n","    \n","    # Store the directory name and file count in the dictionary\n","    directory_file_counts[root] = file_count\n","\n","# Print the directory names and their respective file counts\n","for directory, file_count in directory_file_counts.items():\n","    print(f\"Directory: {directory}, File Count: {file_count}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:28:14.221165Z","iopub.status.busy":"2023-11-30T15:28:14.220807Z","iopub.status.idle":"2023-11-30T15:28:14.231511Z","shell.execute_reply":"2023-11-30T15:28:14.230714Z","shell.execute_reply.started":"2023-11-30T15:28:14.221137Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['disco', 'metal', 'reggae', 'blues', 'rock', 'classical', 'jazz', 'hiphop', 'country', 'pop']\n"]}],"source":["classes = [a for a in os.listdir('/kaggle/input/gtzan-dataset-music-genre-classification/Data/images_original') if '.' not in a]\n","print(classes)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:28:17.080664Z","iopub.status.busy":"2023-11-30T15:28:17.079666Z","iopub.status.idle":"2023-11-30T15:28:29.366988Z","shell.execute_reply":"2023-11-30T15:28:29.365898Z","shell.execute_reply.started":"2023-11-30T15:28:17.080628Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(999, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_32/607387902.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  dataset_toUse = np.array(dataset)\n"]}],"source":["'Create X and Y for: train, valid, test'\n","\n","img_size = 256\n","dataset=[]\n","for label in classes:\n","    path = os.path.join(parent_directory, label)\n","    class_num = classes.index(label)\n","    \n","    for img in os.listdir(path):\n","        try:\n","            img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n","            resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n","            dataset.append([resized_arr, class_num])\n","        except Exception as e:\n","            print(e)\n","\n","dataset_toUse = np.array(dataset)\n","print(dataset_toUse.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:28:29.369116Z","iopub.status.busy":"2023-11-30T15:28:29.368833Z","iopub.status.idle":"2023-11-30T15:28:29.910595Z","shell.execute_reply":"2023-11-30T15:28:29.909625Z","shell.execute_reply.started":"2023-11-30T15:28:29.369091Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(999, 256, 256, 3)\n","(999,)\n"]}],"source":["X = []\n","Y = []\n","for feature, label in dataset_toUse:\n","    X.append(feature)\n","    Y.append(label)\n","\n","X = np.array(X) / 255.\n","Y = np.array(Y)\n","\n","# X = np.load('/kaggle/input/gtzanseg6/X.npy')\n","# Y = np.load('/kaggle/input/gtzanseg6/Y.npy')\n","\n","print(X.shape)\n","print(Y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# **Transfer learning part** #"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:28:29.911870Z","iopub.status.busy":"2023-11-30T15:28:29.911571Z","iopub.status.idle":"2023-11-30T15:28:30.005541Z","shell.execute_reply":"2023-11-30T15:28:30.004847Z","shell.execute_reply.started":"2023-11-30T15:28:29.911844Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import applications, layers, models, regularizers\n","from tensorflow.keras.optimizers import Adam\n","from keras.applications.vgg16 import VGG16\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:28:30.293598Z","iopub.status.busy":"2023-11-30T15:28:30.292910Z","iopub.status.idle":"2023-11-30T15:28:30.826577Z","shell.execute_reply":"2023-11-30T15:28:30.825234Z","shell.execute_reply.started":"2023-11-30T15:28:30.293570Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(799, 256, 256, 3) (799,)\n","(100, 256, 256, 3) (100,)\n","(100, 256, 256, 3) (100,)\n"]}],"source":["x_train, x_aux, y_train, y_aux = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n","x_test, x_valid, y_test, y_valid = train_test_split(x_aux, y_aux, test_size = 0.5, random_state = 42)\n","\n","# x_train.reshape(-1, img_size, img_size, 1)\n","\n","print(x_train.shape, y_train.shape)\n","print(x_valid.shape, y_valid.shape)\n","print(x_test.shape, y_test.shape)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:28:33.302379Z","iopub.status.busy":"2023-11-30T15:28:33.301683Z","iopub.status.idle":"2023-11-30T15:30:01.587405Z","shell.execute_reply":"2023-11-30T15:30:01.586327Z","shell.execute_reply.started":"2023-11-30T15:28:33.302342Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","50/50 [==============================] - 11s 37ms/step - loss: 3.1693 - accuracy: 0.1640 - val_loss: 2.6233 - val_accuracy: 0.2000\n","Epoch 2/40\n","50/50 [==============================] - 1s 20ms/step - loss: 2.3787 - accuracy: 0.3029 - val_loss: 2.2367 - val_accuracy: 0.3100\n","Epoch 3/40\n","50/50 [==============================] - 1s 21ms/step - loss: 2.0701 - accuracy: 0.3605 - val_loss: 2.0084 - val_accuracy: 0.3500\n","Epoch 4/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.9317 - accuracy: 0.4068 - val_loss: 1.8262 - val_accuracy: 0.4400\n","Epoch 5/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.7299 - accuracy: 0.4581 - val_loss: 1.7150 - val_accuracy: 0.4900\n","Epoch 6/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.6702 - accuracy: 0.4706 - val_loss: 1.5777 - val_accuracy: 0.5400\n","Epoch 7/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.6345 - accuracy: 0.4606 - val_loss: 1.4987 - val_accuracy: 0.5400\n","Epoch 8/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.4789 - accuracy: 0.5469 - val_loss: 1.4975 - val_accuracy: 0.5200\n","Epoch 9/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.4420 - accuracy: 0.5419 - val_loss: 1.5064 - val_accuracy: 0.5200\n","Epoch 10/40\n","50/50 [==============================] - 1s 21ms/step - loss: 1.3617 - accuracy: 0.5845 - val_loss: 1.5126 - val_accuracy: 0.5100\n","Epoch 11/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.2875 - accuracy: 0.6070 - val_loss: 1.4034 - val_accuracy: 0.5800\n","Epoch 12/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.2640 - accuracy: 0.6045 - val_loss: 1.3834 - val_accuracy: 0.5800\n","Epoch 13/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.1453 - accuracy: 0.6508 - val_loss: 1.1834 - val_accuracy: 0.6700\n","Epoch 14/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.0836 - accuracy: 0.6533 - val_loss: 1.3046 - val_accuracy: 0.6200\n","Epoch 15/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.9688 - accuracy: 0.7334 - val_loss: 1.3323 - val_accuracy: 0.6300\n","Epoch 16/40\n","50/50 [==============================] - 1s 20ms/step - loss: 1.0184 - accuracy: 0.7034 - val_loss: 1.3411 - val_accuracy: 0.6100\n","Epoch 17/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.9464 - accuracy: 0.7234 - val_loss: 1.3440 - val_accuracy: 0.6600\n","Epoch 18/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.9163 - accuracy: 0.7334 - val_loss: 1.5015 - val_accuracy: 0.5600\n","Epoch 19/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.8244 - accuracy: 0.7747 - val_loss: 1.2623 - val_accuracy: 0.7300\n","Epoch 20/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.7325 - accuracy: 0.8160 - val_loss: 1.4923 - val_accuracy: 0.6500\n","Epoch 21/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.7160 - accuracy: 0.8223 - val_loss: 1.3096 - val_accuracy: 0.6900\n","Epoch 22/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.6309 - accuracy: 0.8486 - val_loss: 1.6596 - val_accuracy: 0.6200\n","Epoch 23/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.5726 - accuracy: 0.8786 - val_loss: 1.7517 - val_accuracy: 0.6000\n","Epoch 24/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.5329 - accuracy: 0.8723 - val_loss: 1.6687 - val_accuracy: 0.6400\n","Epoch 25/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.6297 - accuracy: 0.8486 - val_loss: 1.5943 - val_accuracy: 0.6300\n","Epoch 26/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.5388 - accuracy: 0.8824 - val_loss: 1.6796 - val_accuracy: 0.6500\n","Epoch 27/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.5058 - accuracy: 0.8974 - val_loss: 1.7037 - val_accuracy: 0.6500\n","Epoch 28/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.4652 - accuracy: 0.9061 - val_loss: 1.8427 - val_accuracy: 0.6300\n","Epoch 29/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.3847 - accuracy: 0.9449 - val_loss: 1.7154 - val_accuracy: 0.6600\n","Epoch 30/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.3611 - accuracy: 0.9499 - val_loss: 1.7605 - val_accuracy: 0.6200\n","Epoch 31/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.3595 - accuracy: 0.9474 - val_loss: 1.9164 - val_accuracy: 0.6400\n","Epoch 32/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.4099 - accuracy: 0.9287 - val_loss: 2.0078 - val_accuracy: 0.6100\n","Epoch 33/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.3690 - accuracy: 0.9362 - val_loss: 2.1274 - val_accuracy: 0.6000\n","Epoch 34/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.4968 - accuracy: 0.9036 - val_loss: 1.7707 - val_accuracy: 0.6700\n","Epoch 35/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.3599 - accuracy: 0.9499 - val_loss: 1.8720 - val_accuracy: 0.6200\n","Epoch 36/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.4003 - accuracy: 0.9462 - val_loss: 2.0843 - val_accuracy: 0.6000\n","Epoch 37/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.3597 - accuracy: 0.9562 - val_loss: 1.9500 - val_accuracy: 0.6400\n","Epoch 38/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.2937 - accuracy: 0.9737 - val_loss: 2.2926 - val_accuracy: 0.6400\n","Epoch 39/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.2729 - accuracy: 0.9750 - val_loss: 2.0359 - val_accuracy: 0.6200\n","Epoch 40/40\n","50/50 [==============================] - 1s 20ms/step - loss: 0.2631 - accuracy: 0.9825 - val_loss: 2.1951 - val_accuracy: 0.6500\n","4/4 [==============================] - 0s 14ms/step - loss: 2.5799 - accuracy: 0.5600\n","Test Loss: 2.579878330230713\n","Test Accuracy: 0.5600000023841858\n"]}],"source":["model = Sequential()\n","model.add(Conv2D(32,3,padding=\"same\", activation=tf.keras.layers.LeakyReLU(alpha=0.01), input_shape=(256,256,3), kernel_regularizer='l2'))\n","model.add(MaxPool2D())\n","\n","model.add(Conv2D(32, 3, padding=\"same\", activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_regularizer='l2'))\n","model.add(MaxPool2D())\n","\n","model.add(Conv2D(64, 3, padding=\"same\", activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_regularizer='l2'))\n","model.add(MaxPool2D())\n","\n","model.add(Conv2D(64, 3, padding=\"same\", activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_regularizer='l2'))\n","model.add(MaxPool2D())\n","\n","model.add(Flatten())\n","model.add(Dense(128,activation=tf.keras.layers.LeakyReLU(alpha=0.01)))\n","model.add(Dropout(0.2))\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=40, batch_size=16)\n","\n","# Evaluate the model on the test set\n","results = model.evaluate(x_test, y_test)\n","\n","# Print the evaluation results\n","print(\"Test Loss:\", results[0])\n","print(\"Test Accuracy:\", results[1])\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:30:07.707772Z","iopub.status.busy":"2023-11-30T15:30:07.706901Z","iopub.status.idle":"2023-11-30T15:30:48.172844Z","shell.execute_reply":"2023-11-30T15:30:48.171974Z","shell.execute_reply.started":"2023-11-30T15:30:07.707709Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9406464/9406464 [==============================] - 0s 0us/step\n","Epoch 1/30\n","25/25 [==============================] - 6s 111ms/step - loss: 1.9295 - accuracy: 0.3141 - val_loss: 1.6139 - val_accuracy: 0.4700\n","Epoch 2/30\n","25/25 [==============================] - 1s 42ms/step - loss: 1.4116 - accuracy: 0.4956 - val_loss: 1.4270 - val_accuracy: 0.4900\n","Epoch 3/30\n","25/25 [==============================] - 1s 43ms/step - loss: 1.2256 - accuracy: 0.5820 - val_loss: 1.2634 - val_accuracy: 0.5400\n","Epoch 4/30\n","25/25 [==============================] - 1s 42ms/step - loss: 1.1073 - accuracy: 0.6308 - val_loss: 1.1733 - val_accuracy: 0.5500\n","Epoch 5/30\n","25/25 [==============================] - 1s 42ms/step - loss: 1.0604 - accuracy: 0.6333 - val_loss: 1.2064 - val_accuracy: 0.5500\n","Epoch 6/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.9499 - accuracy: 0.6821 - val_loss: 1.1503 - val_accuracy: 0.5800\n","Epoch 7/30\n","25/25 [==============================] - 1s 44ms/step - loss: 0.8628 - accuracy: 0.7121 - val_loss: 1.0826 - val_accuracy: 0.5900\n","Epoch 8/30\n","25/25 [==============================] - 1s 42ms/step - loss: 0.7952 - accuracy: 0.7334 - val_loss: 1.0736 - val_accuracy: 0.6000\n","Epoch 9/30\n","25/25 [==============================] - 1s 42ms/step - loss: 0.7499 - accuracy: 0.7559 - val_loss: 1.0505 - val_accuracy: 0.6100\n","Epoch 10/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.7331 - accuracy: 0.7697 - val_loss: 1.1492 - val_accuracy: 0.5800\n","Epoch 11/30\n","25/25 [==============================] - 1s 44ms/step - loss: 0.6607 - accuracy: 0.7897 - val_loss: 1.0506 - val_accuracy: 0.6300\n","Epoch 12/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.6422 - accuracy: 0.7997 - val_loss: 1.0032 - val_accuracy: 0.6300\n","Epoch 13/30\n","25/25 [==============================] - 1s 42ms/step - loss: 0.6051 - accuracy: 0.8098 - val_loss: 1.0701 - val_accuracy: 0.5700\n","Epoch 14/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.5637 - accuracy: 0.8210 - val_loss: 0.9487 - val_accuracy: 0.6600\n","Epoch 15/30\n","25/25 [==============================] - 1s 44ms/step - loss: 0.5344 - accuracy: 0.8235 - val_loss: 0.9729 - val_accuracy: 0.6400\n","Epoch 16/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.5120 - accuracy: 0.8398 - val_loss: 1.0031 - val_accuracy: 0.6400\n","Epoch 17/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.5169 - accuracy: 0.8348 - val_loss: 0.9602 - val_accuracy: 0.6400\n","Epoch 18/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.4678 - accuracy: 0.8648 - val_loss: 0.9395 - val_accuracy: 0.6700\n","Epoch 19/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.4449 - accuracy: 0.8773 - val_loss: 0.9569 - val_accuracy: 0.6600\n","Epoch 20/30\n","25/25 [==============================] - 1s 42ms/step - loss: 0.4443 - accuracy: 0.8523 - val_loss: 0.9770 - val_accuracy: 0.6600\n","Epoch 21/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.4352 - accuracy: 0.8673 - val_loss: 1.0231 - val_accuracy: 0.6000\n","Epoch 22/30\n","25/25 [==============================] - 1s 44ms/step - loss: 0.3952 - accuracy: 0.8849 - val_loss: 1.0100 - val_accuracy: 0.6900\n","Epoch 23/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.3841 - accuracy: 0.8886 - val_loss: 0.9349 - val_accuracy: 0.6300\n","Epoch 24/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.3624 - accuracy: 0.8924 - val_loss: 0.9400 - val_accuracy: 0.6900\n","Epoch 25/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.3867 - accuracy: 0.8786 - val_loss: 1.0437 - val_accuracy: 0.6400\n","Epoch 26/30\n","25/25 [==============================] - 1s 43ms/step - loss: 0.3402 - accuracy: 0.9024 - val_loss: 0.9883 - val_accuracy: 0.6500\n","Epoch 27/30\n","25/25 [==============================] - 1s 42ms/step - loss: 0.3124 - accuracy: 0.9199 - val_loss: 0.9722 - val_accuracy: 0.6500\n","Epoch 28/30\n","25/25 [==============================] - 1s 44ms/step - loss: 0.3271 - accuracy: 0.8961 - val_loss: 0.9987 - val_accuracy: 0.6700\n","Epoch 29/30\n","25/25 [==============================] - 1s 42ms/step - loss: 0.2817 - accuracy: 0.9237 - val_loss: 0.9977 - val_accuracy: 0.6800\n","Epoch 30/30\n","25/25 [==============================] - 1s 42ms/step - loss: 0.2862 - accuracy: 0.9199 - val_loss: 0.9371 - val_accuracy: 0.7000\n","4/4 [==============================] - 0s 27ms/step - loss: 0.8211 - accuracy: 0.7600\n","Test Loss: 0.8211221098899841\n","Test Accuracy: 0.7599999904632568\n"]}],"source":["# Load the model chose for transfer learning, excluding the top (classification) layer\n","base_model =  tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","  \n","    \n","x = base_model.output \n","# Add your custom classification head\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.005))(x)\n","x = layers.Dropout(0.2)(x)\n","output = layers.Dense(10, activation='softmax')(x)  # 10 classes for music genres\n","\n","# Create a new model with the custom input and classification head\n","model = models.Model(inputs=base_model.input, outputs=output)\n","\n","# model.summary()\n","\n","# Compile the model\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# callbacks = [EarlyStopping(monitor='val_loss', patience=7, verbose=1)]\n","\n","# Fit the model\n","model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=30, batch_size=32)\n","\n","# Evaluate the model on the test set\n","results = model.evaluate(x_test, y_test)\n","\n","# Print the evaluation results\n","print(\"Test Loss:\", results[0])\n","print(\"Test Accuracy:\", results[1])"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T15:30:48.174620Z","iopub.status.busy":"2023-11-30T15:30:48.174361Z","iopub.status.idle":"2023-11-30T15:33:37.412302Z","shell.execute_reply":"2023-11-30T15:33:37.411382Z","shell.execute_reply.started":"2023-11-30T15:30:48.174597Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83683744/83683744 [==============================] - 0s 0us/step\n","Epoch 1/50\n","100/100 [==============================] - 8s 48ms/step - loss: 2.0697 - accuracy: 0.2466 - val_loss: 1.8996 - val_accuracy: 0.2700\n","Epoch 2/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.6568 - accuracy: 0.4118 - val_loss: 1.6131 - val_accuracy: 0.4000\n","Epoch 3/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.4706 - accuracy: 0.4768 - val_loss: 1.3584 - val_accuracy: 0.5100\n","Epoch 4/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.3410 - accuracy: 0.5056 - val_loss: 1.2559 - val_accuracy: 0.5900\n","Epoch 5/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.3031 - accuracy: 0.5394 - val_loss: 1.3697 - val_accuracy: 0.4400\n","Epoch 6/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.1774 - accuracy: 0.5907 - val_loss: 1.2162 - val_accuracy: 0.5900\n","Epoch 7/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.1374 - accuracy: 0.6045 - val_loss: 1.2948 - val_accuracy: 0.4800\n","Epoch 8/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.1134 - accuracy: 0.5832 - val_loss: 1.1190 - val_accuracy: 0.6200\n","Epoch 9/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.0808 - accuracy: 0.6170 - val_loss: 1.0592 - val_accuracy: 0.6200\n","Epoch 10/50\n","100/100 [==============================] - 3s 32ms/step - loss: 1.0562 - accuracy: 0.6233 - val_loss: 1.1042 - val_accuracy: 0.6200\n","Epoch 11/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.9902 - accuracy: 0.6546 - val_loss: 1.1116 - val_accuracy: 0.6300\n","Epoch 12/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.9641 - accuracy: 0.6671 - val_loss: 1.1657 - val_accuracy: 0.5800\n","Epoch 13/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.9726 - accuracy: 0.6483 - val_loss: 1.0956 - val_accuracy: 0.6500\n","Epoch 14/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.9318 - accuracy: 0.6696 - val_loss: 1.0417 - val_accuracy: 0.6500\n","Epoch 15/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.8933 - accuracy: 0.6971 - val_loss: 1.0202 - val_accuracy: 0.5700\n","Epoch 16/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.8922 - accuracy: 0.6971 - val_loss: 1.0585 - val_accuracy: 0.6300\n","Epoch 17/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.8737 - accuracy: 0.6834 - val_loss: 1.1057 - val_accuracy: 0.6200\n","Epoch 18/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.8500 - accuracy: 0.7297 - val_loss: 1.0398 - val_accuracy: 0.6100\n","Epoch 19/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.7699 - accuracy: 0.7259 - val_loss: 1.0878 - val_accuracy: 0.5800\n","Epoch 20/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.7897 - accuracy: 0.7134 - val_loss: 1.0493 - val_accuracy: 0.5900\n","Epoch 21/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.8120 - accuracy: 0.7109 - val_loss: 1.1195 - val_accuracy: 0.6200\n","Epoch 22/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.7526 - accuracy: 0.7384 - val_loss: 1.0402 - val_accuracy: 0.6500\n","Epoch 23/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.7624 - accuracy: 0.7284 - val_loss: 1.1192 - val_accuracy: 0.5900\n","Epoch 24/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.7425 - accuracy: 0.7309 - val_loss: 1.0915 - val_accuracy: 0.6700\n","Epoch 25/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.7271 - accuracy: 0.7322 - val_loss: 0.9979 - val_accuracy: 0.6600\n","Epoch 26/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.6893 - accuracy: 0.7785 - val_loss: 1.0103 - val_accuracy: 0.6500\n","Epoch 27/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.6577 - accuracy: 0.7622 - val_loss: 1.1305 - val_accuracy: 0.6300\n","Epoch 28/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.6690 - accuracy: 0.7597 - val_loss: 1.0568 - val_accuracy: 0.6600\n","Epoch 29/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.6797 - accuracy: 0.7660 - val_loss: 1.0568 - val_accuracy: 0.6400\n","Epoch 30/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.6887 - accuracy: 0.7660 - val_loss: 1.0190 - val_accuracy: 0.6600\n","Epoch 31/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.6512 - accuracy: 0.7747 - val_loss: 1.0660 - val_accuracy: 0.6300\n","Epoch 32/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.6062 - accuracy: 0.7860 - val_loss: 1.2725 - val_accuracy: 0.6200\n","Epoch 33/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5974 - accuracy: 0.7997 - val_loss: 1.0015 - val_accuracy: 0.6700\n","Epoch 34/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5741 - accuracy: 0.7997 - val_loss: 1.0250 - val_accuracy: 0.6500\n","Epoch 35/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5813 - accuracy: 0.7972 - val_loss: 0.9564 - val_accuracy: 0.6600\n","Epoch 36/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5650 - accuracy: 0.7947 - val_loss: 0.9392 - val_accuracy: 0.7300\n","Epoch 37/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5537 - accuracy: 0.8148 - val_loss: 1.0914 - val_accuracy: 0.6700\n","Epoch 38/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5199 - accuracy: 0.8160 - val_loss: 1.0439 - val_accuracy: 0.6900\n","Epoch 39/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5489 - accuracy: 0.8085 - val_loss: 1.1140 - val_accuracy: 0.6600\n","Epoch 40/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5391 - accuracy: 0.8148 - val_loss: 1.0035 - val_accuracy: 0.6800\n","Epoch 41/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.5173 - accuracy: 0.8260 - val_loss: 1.0038 - val_accuracy: 0.6500\n","Epoch 42/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4730 - accuracy: 0.8398 - val_loss: 0.9977 - val_accuracy: 0.6800\n","Epoch 43/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4874 - accuracy: 0.8248 - val_loss: 1.1350 - val_accuracy: 0.6200\n","Epoch 44/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4925 - accuracy: 0.8335 - val_loss: 1.0808 - val_accuracy: 0.6700\n","Epoch 45/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4765 - accuracy: 0.8285 - val_loss: 1.1273 - val_accuracy: 0.6600\n","Epoch 46/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4594 - accuracy: 0.8473 - val_loss: 1.0664 - val_accuracy: 0.6700\n","Epoch 47/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4855 - accuracy: 0.8411 - val_loss: 0.9621 - val_accuracy: 0.7000\n","Epoch 48/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4399 - accuracy: 0.8536 - val_loss: 1.0501 - val_accuracy: 0.6100\n","Epoch 49/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.4332 - accuracy: 0.8461 - val_loss: 1.0706 - val_accuracy: 0.6600\n","Epoch 50/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.4214 - accuracy: 0.8523 - val_loss: 1.0954 - val_accuracy: 0.6700\n","4/4 [==============================] - 1s 71ms/step - loss: 1.2362 - accuracy: 0.6600\n","Test Loss: 1.2361987829208374\n","Test Accuracy: 0.6600000262260437\n"]}],"source":["from tensorflow.keras.applications import Xception\n","\n","base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n","# Freeze the layers of the pre-trained model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","    \n","base_model.layers[-1].trainable = True\n","\n","# Define the custom classification head\n","x = base_model.output\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(128, activation='relu')(x)\n","x = layers.Dropout(0.2)(x)\n","output = layers.Dense(10, activation='softmax')(x)  # 10 classes for music genres\n","\n","# Create a new model with the custom input and classification head\n","model = models.Model(inputs=base_model.input, outputs=output)\n","\n","# Compile the model\n","model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum = 0.7), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=50, batch_size=8)\n","\n","# Evaluate the model on the test set\n","results = model.evaluate(x_test, y_test)\n","# Print the evaluation results\n","print(\"Test Loss:\", results[0])\n","print(\"Test Accuracy:\", results[1])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":568973,"sourceId":1032238,"sourceType":"datasetVersion"},{"datasetId":3940502,"sourceId":6855464,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
